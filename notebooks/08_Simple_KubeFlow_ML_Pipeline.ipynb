{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple KubeFlow Pipeline\n",
    "\n",
    "Lightweight python components do not require you to build a new container image for every code change.\n",
    "They're intended to use for fast iteration in notebook environment.\n",
    "\n",
    "#### Building a lightweight python component\n",
    "To build a component just define a stand-alone python function and then call kfp.components.func_to_container_op(func) to convert it to a component that can be used in a pipeline.\n",
    "\n",
    "There are several requirements for the function:\n",
    "* The function should be stand-alone. It should not use any code declared outside of the function definition. Any imports should be added inside the main function. Any helper functions should also be defined inside the main function.\n",
    "* The function can only import packages that are available in the base image. If you need to import a package that's not available you can try to find a container image that already includes the required packages. (As a workaround you can use the module subprocess to run pip install for the required package.)\n",
    "* If the function operates on numbers, the parameters need to have type hints. Supported types are ```[int, float, bool]```. Everything else is passed as string.\n",
    "* To build a component with multiple output values, use the typing.NamedTuple type hint syntax: ```NamedTuple('MyFunctionOutputs', [('output_name_1', type), ('output_name_2', float)])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://storage.googleapis.com/ml-pipeline/release/0.1.16/kfp.tar.gz\n",
      "\u001b[?25l  Downloading https://storage.googleapis.com/ml-pipeline/release/0.1.16/kfp.tar.gz (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 30.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3>=1.15 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from kfp==0.1) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kfp==0.1) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.6/site-packages (from kfp==0.1) (3.13)\n",
      "Collecting google-cloud-storage==1.13.0 (from kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/62/a2e3111bf4d1eb54fe86dec694418644e024eb059bf1e66ebdcf9f98ad70/google_cloud_storage-1.13.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kubernetes==8.0.0 (from kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/44/f8286fb7a25a4ff29a4dec1b5baa49571eedc2b2edf6ec4b51e4b511ac0f/kubernetes-8.0.0-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 16.6MB/s ta 0:00:01    84% |███████████████████████████     | 1.1MB 64.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyJWT==1.6.4 (from kfp==0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/d1/3378cc8184a6524dc92993090ee8b4c03847c567e298305d6cf86987e005/PyJWT-1.6.4-py2.py3-none-any.whl\n",
      "Collecting cryptography==2.4.2 (from kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c7/99b33c53cf3f20a97a4c4bfd3ab66dcc93d99da0a97cc9597aa36ae6bb62/cryptography-2.4.2-cp34-abi3-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.1MB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth==1.6.1 (from kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/62/8b9612b1055cfbecd577e252446fe5f939f6818d0b7ddc27bb872f233cd4/google_auth-1.6.1-py2.py3-none-any.whl (68kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 16.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests_toolbelt==0.8.0 (from kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/8a/d710f792d6f6ecc089c5e55b66e66c3f2f35516a1ede5a8f54c13350ffb0/requests_toolbelt-0.8.0-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 24.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=0.1.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage==1.13.0->kfp==0.1) (1.9.0)\n",
      "Collecting google-cloud-core<0.29dev,>=0.28.0 (from google-cloud-storage==1.13.0->kfp==0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/41/ae2418b4003a14cf21c1c46d61d1b044bf02cf0f8f91598af572b9216515/google_cloud_core-0.28.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage==1.13.0->kfp==0.1) (0.3.2)\n",
      "Collecting adal>=1.0.2 (from kubernetes==8.0.0->kfp==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/72/53dce9e4f5d6c1aa57b8d408cb34dff1969ecbf10ab7e678f32c5e0e2397/adal-1.2.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 18.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes==8.0.0->kfp==0.1) (0.56.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes==8.0.0->kfp==0.1) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from kubernetes==8.0.0->kfp==0.1) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes==8.0.0->kfp==0.1) (40.9.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography==2.4.2->kfp==0.1) (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.1 in /opt/conda/lib/python3.6/site-packages (from cryptography==2.4.2->kfp==0.1) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography==2.4.2->kfp==0.1) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth==1.6.1->kfp==0.1) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth==1.6.1->kfp==0.1) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth==1.6.1->kfp==0.1) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage==1.13.0->kfp==0.1) (1.5.9)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage==1.13.0->kfp==0.1) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage==1.13.0->kfp==0.1) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes==8.0.0->kfp==0.1) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes==8.0.0->kfp==0.1) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography==2.4.2->kfp==0.1) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth==1.6.1->kfp==0.1) (0.4.5)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /var/tmp/pip-ephem-wheel-cache-x_5atiz2/wheels/6e/b9/57/547b05d1f09ae798e899082c8ea2a7d693bde2e32f56f0792c\n",
      "Successfully built kfp\n",
      "\u001b[31mgoogle-cloud-datastore 1.7.4 has requirement google-cloud-core<2.0dev,>=0.29.0, but you'll have google-cloud-core 0.28.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-cloud-bigtable 0.32.2 has requirement google-cloud-core<2.0dev,>=0.29.0, but you'll have google-cloud-core 0.28.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mfairing 0.5 has requirement google-auth>=1.6.2, but you'll have google-auth 1.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mfairing 0.5 has requirement google-cloud-storage>=1.13.2, but you'll have google-cloud-storage 1.13.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mfairing 0.5 has requirement kubernetes>=9.0.0, but you'll have kubernetes 8.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mfairing 0.5 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: google-cloud-core, google-cloud-storage, google-auth, cryptography, PyJWT, adal, kubernetes, requests-toolbelt, kfp\n",
      "  Found existing installation: google-cloud-core 0.29.1\n",
      "    Uninstalling google-cloud-core-0.29.1:\n",
      "      Successfully uninstalled google-cloud-core-0.29.1\n",
      "  Found existing installation: google-cloud-storage 1.14.0\n",
      "    Uninstalling google-cloud-storage-1.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-1.14.0\n",
      "  Found existing installation: google-auth 1.6.3\n",
      "    Uninstalling google-auth-1.6.3:\n",
      "      Successfully uninstalled google-auth-1.6.3\n",
      "  Found existing installation: cryptography 2.6.1\n",
      "    Uninstalling cryptography-2.6.1:\n",
      "      Successfully uninstalled cryptography-2.6.1\n",
      "  Found existing installation: kubernetes 9.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling kubernetes-9.0.0:\n",
      "      Successfully uninstalled kubernetes-9.0.0\n",
      "  Found existing installation: kfp 0.1\n",
      "    Uninstalling kfp-0.1:\n",
      "      Successfully uninstalled kfp-0.1\n",
      "Successfully installed PyJWT-1.6.4 adal-1.2.1 cryptography-2.4.2 google-auth-1.6.1 google-cloud-core-0.28.1 google-cloud-storage-1.13.0 kfp-0.1 kubernetes-8.0.0 requests-toolbelt-0.8.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the KubeFlow Pipeline SDK\n",
    "!pip3 install https://storage.googleapis.com/ml-pipeline/release/0.1.16/kfp.tar.gz --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function that just add two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Python function\n",
    "def add_fn(a: float, b: float) -> float:\n",
    "   '''Calculates sum of two arguments'''\n",
    "   return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the function to a pipeline operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "\n",
    "add_op = comp.func_to_container_op(add_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit more advanced function which demonstrates how to use imports, helper functions and produce multiple outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def div_fn(dividend: float, divisor:float, output_dir:str = './') -> NamedTuple('DivOutput', [('quotient', float), ('remainder', float)]):\n",
    "    '''Divides two numbers and calculate  the quotient and remainder'''\n",
    "    #Imports inside a component function:\n",
    "    import numpy as np\n",
    "\n",
    "    #This function demonstrates how to use nested functions inside a component function:\n",
    "    def nested_div_helper(dividend, divisor):\n",
    "        return np.divmod(dividend, divisor)\n",
    "\n",
    "    (quotient, remainder) = nested_div_helper(dividend, divisor)\n",
    "\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    import json\n",
    "    \n",
    "    # Exports two sample metrics:\n",
    "    metrics = {\n",
    "      'metrics': [{\n",
    "          'name': 'quotient',\n",
    "          'numberValue':  float(quotient),\n",
    "        },{\n",
    "          'name': 'remainder',\n",
    "          'numberValue':  float(remainder),\n",
    "        }]}\n",
    "\n",
    "    with file_io.FileIO(output_dir + 'mlpipeline-metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    output = namedtuple('DivOutput', ['quotient', 'remainder'])\n",
    "    return output(quotient, remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test running the python function directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DivOutput(quotient=14, remainder=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_fn(100, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the function to a pipeline operation\n",
    "\n",
    "You can specify an alternative base container image (the image needs to have Python 3.5+ installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_op = comp.func_to_container_op(div_fn, base_image='tensorflow/tensorflow:1.11.0-py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "Pipeline function has to be decorated with the `@dsl.pipeline` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Calculation pipeline',\n",
    "   description='A toy pipeline that performs arithmetic calculations.'\n",
    ")\n",
    "def add_div_pipeline(\n",
    "   a='a',\n",
    "   b='7',\n",
    "   c='17',\n",
    "):\n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "    add_task = add_op(a, 4) #Returns a dsl.ContainerOp class instance. \n",
    "    \n",
    "    #Passing a task output reference as operation arguments\n",
    "    #For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "    div_task = div_op(add_task.output, b, '/')\n",
    "\n",
    "    #For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax\n",
    "    result_task = add_op(div_task.outputs['quotient'], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = add_div_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.tar.gz'\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.yaml\n",
      "apiVersion: argoproj.io/v1alpha1\n",
      "kind: Workflow\n",
      "metadata:\n",
      "  generateName: calculation-pipeline-\n",
      "spec:\n",
      "  arguments:\n",
      "    parameters:\n",
      "    - name: a\n",
      "      value: a\n",
      "    - name: b\n",
      "      value: '7'\n",
      "    - name: c\n",
      "      value: '17'\n",
      "  entrypoint: calculation-pipeline\n",
      "  serviceAccountName: pipeline-runner\n",
      "  templates:\n",
      "  - container:\n",
      "      args:\n",
      "      - '{{inputs.parameters.a}}'\n",
      "      - '4'\n",
      "      - /outputs/Output/data\n",
      "      command:\n",
      "      - python3\n",
      "      - -c\n",
      "      - \"def add_fn(a: float, b: float) -> float:\\n   '''Calculates sum of two arguments'''\\n\\\n",
      "        \\   return a + b\\n\\nimport sys\\n_args = {\\n    'a': float(sys.argv[1]),\\n\\\n",
      "        \\    'b': float(sys.argv[2]),\\n}\\n_output_files = [\\n    sys.argv[3],\\n]\\n\\\n",
      "        \\n_outputs = add_fn(**_args)\\n\\nif not hasattr(_outputs, '__getitem__') or\\\n",
      "        \\ isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\nfrom pathlib import\\\n",
      "        \\ Path\\nfor idx, filename in enumerate(_output_files):\\n    _output_path =\\\n",
      "        \\ Path(filename)\\n    _output_path.parent.mkdir(parents=True, exist_ok=True)\\n\\\n",
      "        \\    _output_path.write_text(str(_outputs[idx]))\\n\"\n",
      "      image: tensorflow/tensorflow:1.11.0-py3\n",
      "    inputs:\n",
      "      parameters:\n",
      "      - name: a\n",
      "    name: add-fn\n",
      "    outputs:\n",
      "      artifacts:\n",
      "      - name: mlpipeline-ui-metadata\n",
      "        path: /mlpipeline-ui-metadata.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      - name: mlpipeline-metrics\n",
      "        path: /mlpipeline-metrics.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      parameters:\n",
      "      - name: add-fn-output\n",
      "        valueFrom:\n",
      "          path: /outputs/Output/data\n",
      "  - container:\n",
      "      args:\n",
      "      - '{{inputs.parameters.div-fn-quotient}}'\n",
      "      - '{{inputs.parameters.c}}'\n",
      "      - /outputs/Output/data\n",
      "      command:\n",
      "      - python3\n",
      "      - -c\n",
      "      - \"def add_fn(a: float, b: float) -> float:\\n   '''Calculates sum of two arguments'''\\n\\\n",
      "        \\   return a + b\\n\\nimport sys\\n_args = {\\n    'a': float(sys.argv[1]),\\n\\\n",
      "        \\    'b': float(sys.argv[2]),\\n}\\n_output_files = [\\n    sys.argv[3],\\n]\\n\\\n",
      "        \\n_outputs = add_fn(**_args)\\n\\nif not hasattr(_outputs, '__getitem__') or\\\n",
      "        \\ isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\nfrom pathlib import\\\n",
      "        \\ Path\\nfor idx, filename in enumerate(_output_files):\\n    _output_path =\\\n",
      "        \\ Path(filename)\\n    _output_path.parent.mkdir(parents=True, exist_ok=True)\\n\\\n",
      "        \\    _output_path.write_text(str(_outputs[idx]))\\n\"\n",
      "      image: tensorflow/tensorflow:1.11.0-py3\n",
      "    inputs:\n",
      "      parameters:\n",
      "      - name: c\n",
      "      - name: div-fn-quotient\n",
      "    name: add-fn-2\n",
      "    outputs:\n",
      "      artifacts:\n",
      "      - name: mlpipeline-ui-metadata\n",
      "        path: /mlpipeline-ui-metadata.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      - name: mlpipeline-metrics\n",
      "        path: /mlpipeline-metrics.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      parameters:\n",
      "      - name: add-fn-2-output\n",
      "        valueFrom:\n",
      "          path: /outputs/Output/data\n",
      "  - dag:\n",
      "      tasks:\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: a\n",
      "            value: '{{inputs.parameters.a}}'\n",
      "        name: add-fn\n",
      "        template: add-fn\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: c\n",
      "            value: '{{inputs.parameters.c}}'\n",
      "          - name: div-fn-quotient\n",
      "            value: '{{tasks.div-fn.outputs.parameters.div-fn-quotient}}'\n",
      "        dependencies:\n",
      "        - div-fn\n",
      "        name: add-fn-2\n",
      "        template: add-fn-2\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: add-fn-output\n",
      "            value: '{{tasks.add-fn.outputs.parameters.add-fn-output}}'\n",
      "          - name: b\n",
      "            value: '{{inputs.parameters.b}}'\n",
      "        dependencies:\n",
      "        - add-fn\n",
      "        name: div-fn\n",
      "        template: div-fn\n",
      "    inputs:\n",
      "      parameters:\n",
      "      - name: a\n",
      "      - name: b\n",
      "      - name: c\n",
      "    name: calculation-pipeline\n",
      "  - container:\n",
      "      args:\n",
      "      - '{{inputs.parameters.add-fn-output}}'\n",
      "      - '{{inputs.parameters.b}}'\n",
      "      - /\n",
      "      - /outputs/quotient/data\n",
      "      - /outputs/remainder/data\n",
      "      command:\n",
      "      - python3\n",
      "      - -c\n",
      "      - \"from typing import NamedTuple\\n\\ndef div_fn(dividend: float, divisor:float,\\\n",
      "        \\ output_dir:str = './') -> NamedTuple('DivOutput', [('quotient', float),\\\n",
      "        \\ ('remainder', float)]):\\n    '''Divides two numbers and calculate  the quotient\\\n",
      "        \\ and remainder'''\\n    #Imports inside a component function:\\n    import\\\n",
      "        \\ numpy as np\\n\\n    #This function demonstrates how to use nested functions\\\n",
      "        \\ inside a component function:\\n    def nested_div_helper(dividend, divisor):\\n\\\n",
      "        \\        return np.divmod(dividend, divisor)\\n\\n    (quotient, remainder)\\\n",
      "        \\ = nested_div_helper(dividend, divisor)\\n\\n    from tensorflow.python.lib.io\\\n",
      "        \\ import file_io\\n    import json\\n    \\n    # Exports two sample metrics:\\n\\\n",
      "        \\    metrics = {\\n      'metrics': [{\\n          'name': 'quotient',\\n   \\\n",
      "        \\       'numberValue':  float(quotient),\\n        },{\\n          'name': 'remainder',\\n\\\n",
      "        \\          'numberValue':  float(remainder),\\n        }]}\\n\\n    with file_io.FileIO(output_dir\\\n",
      "        \\ + 'mlpipeline-metrics.json', 'w') as f:\\n        json.dump(metrics, f)\\n\\\n",
      "        \\n    from collections import namedtuple\\n    output = namedtuple('DivOutput',\\\n",
      "        \\ ['quotient', 'remainder'])\\n    return output(quotient, remainder)\\n\\nimport\\\n",
      "        \\ sys\\n_args = {\\n    'dividend': float(sys.argv[1]),\\n    'divisor': float(sys.argv[2]),\\n\\\n",
      "        \\    'output_dir': str(sys.argv[3]),\\n}\\n_output_files = [\\n    sys.argv[4],\\n\\\n",
      "        \\    sys.argv[5],\\n]\\n\\n_outputs = div_fn(**_args)\\n\\nif not hasattr(_outputs,\\\n",
      "        \\ '__getitem__') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\\n",
      "        \\nfrom pathlib import Path\\nfor idx, filename in enumerate(_output_files):\\n\\\n",
      "        \\    _output_path = Path(filename)\\n    _output_path.parent.mkdir(parents=True,\\\n",
      "        \\ exist_ok=True)\\n    _output_path.write_text(str(_outputs[idx]))\\n\"\n",
      "      image: tensorflow/tensorflow:1.11.0-py3\n",
      "    inputs:\n",
      "      parameters:\n",
      "      - name: add-fn-output\n",
      "      - name: b\n",
      "    name: div-fn\n",
      "    outputs:\n",
      "      artifacts:\n",
      "      - name: mlpipeline-ui-metadata\n",
      "        path: /mlpipeline-ui-metadata.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      - name: mlpipeline-metrics\n",
      "        path: /mlpipeline-metrics.json\n",
      "        s3:\n",
      "          accessKeySecret:\n",
      "            key: accesskey\n",
      "            name: mlpipeline-minio-artifact\n",
      "          bucket: mlpipeline\n",
      "          endpoint: minio-service.kubeflow:9000\n",
      "          insecure: true\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\n",
      "          secretKeySecret:\n",
      "            key: secretkey\n",
      "            name: mlpipeline-minio-artifact\n",
      "      parameters:\n",
      "      - name: div-fn-quotient\n",
      "        valueFrom:\n",
      "          path: /outputs/quotient/data\n",
      "      - name: div-fn-remainder\n",
      "        valueFrom:\n",
      "          path: /outputs/remainder/data\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf add_div_pipeline.pipeline.tar.gz\n",
    "!cat pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/5e556e9f-297f-4168-983d-1ef93e78943e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/f10aeae8-8fa9-11e9-bf6e-42010a800037\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {'a': '7', 'b': '8'}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment('simple_add_div_pipeline')\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
